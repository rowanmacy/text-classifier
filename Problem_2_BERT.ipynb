{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rowanmacy/text-classifier/blob/main/Problem_2_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "eZghPtuGE7tf"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import textwrap\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8')\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set('notebook', font_scale=1.25, style='whitegrid')\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "from scipy.stats import uniform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "2Szx8w-ETEW9"
      },
      "outputs": [],
      "source": [
        "# TODOs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9JYd8jlkUKj",
        "outputId": "bafa3773-86c2-4cac-ebca-02d4d0a48c62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'text-classifier'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 72 (delta 17), reused 30 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (72/72), 31.50 MiB | 13.52 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone repo\n",
        "!rm -rf /content/text-classifier  # clear any existing clone\n",
        "!git clone \"https://github.com/rowanmacy/text-classifier/\"  # clone repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GX61uNgfluUa",
        "outputId": "b8077041-af6b-4a62-852f-879c9c5a6851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_test_BERT_embeddings.npz  x_train_BERT_embeddings.npz  y_train.csv\n",
            "x_test.csv\t\t    x_train.csv\n"
          ]
        }
      ],
      "source": [
        "# Check repo contents\n",
        "!ls /content/text-classifier/starter_code/data_readinglevel/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MHieGFd5MvM"
      },
      "source": [
        "## Read in data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "RfzgUgD2Ej1o"
      },
      "outputs": [],
      "source": [
        "# Read in training data\n",
        "x_dev = np.array(np.load(\"/content/text-classifier/starter_code/data_readinglevel/x_train_BERT_embeddings.npz\")['arr_0'])\n",
        "y_dev = pd.read_csv(\"/content/text-classifier/starter_code/data_readinglevel/y_train.csv\")\n",
        "x_test  = np.array(np.load(\"/content/text-classifier/starter_code/data_readinglevel/x_test_BERT_embeddings.npz\")['arr_0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "8Qv5tv_TgAzn"
      },
      "outputs": [],
      "source": [
        "# Convert coarse label into binary classification\n",
        "y_dev['Class'] = (y_dev['Coarse Label'] == 'Key Stage 4-5').astype(int)\n",
        "y_dev = y_dev['Class']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlspA5AXbDW-"
      },
      "source": [
        "## Pre-defined split for proxy test set (validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "2LOF6rxkbGVk"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(x_dev, y_dev, test_size=0.2, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZvOin4FDgbb"
      },
      "source": [
        "## Set up pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "BM4RLP-4hUc2"
      },
      "outputs": [],
      "source": [
        "# Define pipeline for preprocessing and classifier\n",
        "problem_1_pipeline = Pipeline([\n",
        "     ('problem_2_model', LogisticRegression(max_iter=500, random_state=101, penalty='l1')),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0H59oeR5Qtk"
      },
      "source": [
        "## Create RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "jfyzb3HuiH3y"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameter grid to search and scoring metric\n",
        "distributions = dict()\n",
        "\n",
        "# Model parameters\n",
        "distributions['problem_2_model__C'] = np.logspace(-6, 6, 1000)\n",
        "distributions['problem_2_model__solver'] = ['lbfgs', 'saga', 'liblinear']\n",
        "distributions['problem_2_model__penalty'] = ['l1', 'l2']\n",
        "\n",
        "# Preprocessor parameters\n",
        "scoring_metric = 'roc_auc'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "T2Gclg5OnU-o"
      },
      "outputs": [],
      "source": [
        "# Define RandomizedSearchCV and fit to training data\n",
        "random_searcher = RandomizedSearchCV(\n",
        "    problem_1_pipeline,\n",
        "    distributions,\n",
        "    n_iter=50,  # increases number of parameter combinations tried\n",
        "    scoring=scoring_metric,\n",
        "    cv=KFold(n_splits=5, shuffle=True), # Always good to shuffle\n",
        "    refit=True, # Automatically retrain the best-performing model on all available data\n",
        "    verbose = 1,\n",
        "    random_state=101,\n",
        "\n",
        "    error_score = 'raise')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQ_T_GL7pywG",
        "outputId": "4f60a2c6-0614-4ddc-b8af-3bb9164bf5a1"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ]
        }
      ],
      "source": [
        "# Fit random_searcher object to training data\n",
        "random_searcher.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuOjfhggmICP"
      },
      "outputs": [],
      "source": [
        "# Print result of search\n",
        "problem_1_hyp_results = pd.DataFrame(random_searcher.cv_results_).copy()\n",
        "param_keys = ['param_'+str(key) for key in random_searcher.best_params_.keys()]\n",
        "\n",
        "# Rearrange row order\n",
        "problem_1_hyp_results.sort_values(param_keys, inplace=True)\n",
        "\n",
        "# Visualize\n",
        "problem_1_hyp_results[param_keys + ['mean_test_score', 'rank_test_score']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0V53k_BfmA95"
      },
      "outputs": [],
      "source": [
        "# Capture best hyperparameters\n",
        "problem_1_params = random_searcher.best_params_\n",
        "\n",
        "for param, value in problem_1_params.items():\n",
        "  print(param, ':', value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDbALuwz5WP6"
      },
      "source": [
        "## Make predictions and plot ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5N097vz0OM_"
      },
      "outputs": [],
      "source": [
        "# Evaluate performance on training and validation data\n",
        "yhat_tr = random_searcher.predict_proba(X_train)[:,1]\n",
        "yhat_val = random_searcher.predict_proba(X_val)[:,1]\n",
        "\n",
        "# Calculate AUROC for training and validation predictions\n",
        "roc_auc_tr = roc_auc_score(y_train, yhat_tr)\n",
        "roc_auc_val = roc_auc_score(y_val, yhat_val)\n",
        "print('Training score:', round(roc_auc_tr, 3))\n",
        "print('Validation score:', round(roc_auc_val, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tq8w9x4J979X"
      },
      "outputs": [],
      "source": [
        "# Print confusion matrices at 50% threshold\n",
        "print('Training CF:\\n', confusion_matrix(y_train, yhat_tr >= 0.5))\n",
        "print('\\nValidation CF:\\n', confusion_matrix(y_val, yhat_val >= 0.5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLslcUl5-IB7"
      },
      "outputs": [],
      "source": [
        "# Print ROC curves\n",
        "tr_fpr, tr_tpr, tr_thresholds = roc_curve(y_train, yhat_tr)\n",
        "val_fpr, val_tpr, val_thresholds = roc_curve(y_val, yhat_val)\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(tr_fpr, tr_tpr, 'g.-', label='Training')\n",
        "plt.plot(val_fpr, val_tpr, 'r.-', label='Validation')\n",
        "\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('Problem 1 ROC Curve')\n",
        "plt.legend(loc='lower right')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}